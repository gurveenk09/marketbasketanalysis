{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ls_new.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if it changed to datetime\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'date' in ascending order\n",
    "df = df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a subset for school holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset for dates between 13th April and 28th April\n",
    "start_date = '2024-04-13'\n",
    "end_date = '2024-04-28'\n",
    "\n",
    "school_holidays = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to find the number of transactions during last school holidays\n",
    "school_holidays['ReceiptNumber'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_remove = ['Paper Checkout Bags','Discount', 'Clearance']\n",
    "\n",
    "filtered_df = school_holidays[~school_holidays['Details'].isin(items_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Quantity' is integer and handle NaNs\n",
    "filtered_df['Quantity'] = filtered_df['Quantity'].fillna(0).astype(int)\n",
    "\n",
    "# Repeat 'Details' by 'Quantity' to calculate the real item quantity sold in each row\n",
    "repeated_details = filtered_df.apply(lambda row: [row['Details']] * row['Quantity'], axis=1)\n",
    "\n",
    "# Flatten the list of lists\n",
    "flattened_details = [item for sublist in repeated_details for item in sublist]\n",
    "\n",
    "# Calculate value counts\n",
    "details_counts = pd.Series(flattened_details).value_counts().reset_index()\n",
    "\n",
    "details_counts.columns = ['NameofProduct', 'PurchaseFrequencyDuringHolidays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_counts['PurchaseFrequencyDuringHolidays'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_counts.to_csv('HighestProductsSoldDuringHolidays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_line_df = filtered_df[['ReceiptNumber', 'Details']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transaction data into a one-hot encoded format\n",
    "# Get unique items\n",
    "unique_items = sales_line_df['Details'].unique()\n",
    "# Transform to Table Format (One-Hot Encoding)\n",
    "df_retail_txn_table = sales_line_df.pivot_table(index='ReceiptNumber', columns='Details', aggfunc='size', fill_value=0)\n",
    "df_retail_txn_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see we have the count, which may be >1 for some cases. We'll change this to binary to align with the format.\n",
    "df_retail_txn_table = (df_retail_txn_table > 0).astype(int) # This one sets all 1+ values to True & convert it to 1\n",
    "df_retail_txn_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first convert the DataFrame to have Boolean (True/False) instead of 1/0\n",
    "df_retail_final=(df_retail_txn_table > 0)\n",
    "df_retail_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Apriori algorithm to find frequent itemsets\n",
    "min_support = 0.003  # Minimum support threshold - change this number and run again\n",
    "frequent_itemsets = apriori(df_retail_final, min_support=min_support, use_colnames=True)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover association rules\n",
    "min_confidence = 0.01  # Minimum confidence threshold\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=min_confidence)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compile a final list with some filter, calculation & sorting\n",
    "final_rules=rules[(rules['lift']>1)&(rules['support']>=0.001)&(rules['confidence']<=0.09)]\n",
    "# Determine number of items in X => predicting number of items in Y\n",
    "final_rules=final_rules.copy() # this step creates an independent list instead of a view on rules from above\n",
    "# We capture the number of items in the list of each antecedent/consequent set using 'len' function for each row\n",
    "final_rules['antecedent_count']=final_rules['antecedents'].apply(len)\n",
    "final_rules['consequent_count']=final_rules['consequents'].apply(len) #X\n",
    "\n",
    "# Apply some rounding and sorting on Lift\n",
    "final_rules=round(final_rules,2).sort_values(by=['lift', 'confidence'], ascending=[False, False])\n",
    "\n",
    "# Preserve relevant columns only\n",
    "final_rules=final_rules[['antecedents', 'antecedent_count', 'consequents', 'consequent_count', 'support', 'confidence', 'lift']]\n",
    "final_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rules.to_csv('school_holidays.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
